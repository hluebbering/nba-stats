{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use Python and the NBA API to develop advanced machine learning model that predicts player performance metrics in upcoming game\n",
    "\n",
    "\n",
    "<h3 style=\"color:black;font-family:'Segoe UI Variable Display';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;font-weight:300;line-height:1;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Notes from Paris';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;line-height:1;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Juicy Advice Outline';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Mencken Std';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Digital-7';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Proxima Nova';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Barlow Condensed';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "\n",
    "\n",
    "<h3 style=\"color:black;font-family:'Lazy Crunch';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Abril Display';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;\">Part 2.0</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fetching Data ===\n",
      "üîÑ Loading bulk logs from cache: cache/bulk_logs_2024-25.parquet\n",
      "  ‚úÖ Processed data for Nikola Jokiƒá\n",
      "  ‚úÖ Processed data for Shai Gilgeous-Alexander\n",
      "  ‚úÖ Processed data for Anthony Edwards\n",
      "  ‚úÖ Processed data for Tyrese Haliburton\n",
      "=== Applying Aggregators ===\n",
      "\n",
      "=== Training Model ===\n",
      "üî¢  Preparing to split 0 samples\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough data (0 rows) to train/test split",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# --- Train & Evaluate Model ---\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training Model ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m X_train_scaled, X_test_scaled, y_train, y_test, X_test_original \u001b[38;5;241m=\u001b[39m prepare_data(all_player_data)\n\u001b[0;32m     71\u001b[0m best_model \u001b[38;5;241m=\u001b[39m train_models(X_train_scaled, y_train, X_test_scaled, y_test)\n\u001b[0;32m     72\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m evaluate_model(best_model, X_test_scaled, y_test, X_test_original)\n",
      "File \u001b[1;32mc:\\Users\\luebh\\OneDrive\\Desktop\\hluebbering.github.io\\nba-stats\\src\\model_training.py:52\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(df, feature_cols)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# 3. Need at least 2 samples to split\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough data (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows) to train/test split\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 4. Do train/test split\u001b[39;00m\n\u001b[0;32m     55\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     56\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     57\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Not enough data (0 rows) to train/test split"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "import pandas as pd\n",
    "\n",
    "from src.data_ingestion import (\n",
    "    fetch_bulk_player_game_logs,\n",
    "    get_player_game_logs,\n",
    "    get_player_advanced_stats_parallel,\n",
    "    get_opponent_stats      # ‚Üê add this line\n",
    ")\n",
    "from src.feature_engineering import feature_engineering_pipeline\n",
    "from src.model_training import prepare_data, train_models, evaluate_model, DEFAULT_FEATURE_COLS\n",
    "from src.utils import get_player_id, get_team_abbreviation_id_mapping\n",
    "from src.aggregators import (\n",
    "    add_opponent_position_allowed_pts,\n",
    "    add_team_vs_opponent_allowed_pts\n",
    ")\n",
    "from src.data_ingestion import get_opponent_stats_last10\n",
    "\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "PLAYER_NAMES = [\n",
    "    \"Nikola Jokiƒá\", \"Shai Gilgeous-Alexander\", \"Anthony Edwards\", \"Tyrese Haliburton\",\n",
    "    \"Paskal Siakam\", \"Jaylen Williams\", \"Chet Holmgren\"\n",
    "]\n",
    "season = '2024-25'\n",
    "\n",
    "# --- Fetch & Process Data ---\n",
    "print(\"=== Fetching Data ===\")\n",
    "bulk_logs_df = fetch_bulk_player_game_logs(season)\n",
    "team_map = get_team_abbreviation_id_mapping()\n",
    "opp_df = get_opponent_stats(season)   # ‚Üê add this line\n",
    "opp_last10_df = get_opponent_stats_last10(season)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_player_data = pd.DataFrame()\n",
    "\n",
    "for name in PLAYER_NAMES:\n",
    "    pid = get_player_id(name)\n",
    "    if not pid:\n",
    "        continue\n",
    "\n",
    "    logs = get_player_game_logs(pid, bulk_logs_df)\n",
    "    if logs.empty:\n",
    "        continue\n",
    "\n",
    "    game_ids = logs['GAME_ID'].tolist()\n",
    "    adv_stats = get_player_advanced_stats_parallel(pid, game_ids)\n",
    "    if adv_stats.empty:\n",
    "        continue\n",
    "\n",
    "    logs['PLAYER_NAME'] = name\n",
    "    merged = logs.merge(adv_stats, on=['GAME_ID', 'PLAYER_ID'], how='left')\n",
    "    merged['PLAYER_ID'] = pid\n",
    "\n",
    "    # Feature engineering\n",
    "    processed = feature_engineering_pipeline(merged, team_map=team_map,opp_df=opp_df, opp_last10_df=opp_last10_df )\n",
    "    all_player_data = pd.concat([all_player_data, processed], ignore_index=True)\n",
    "    print(f\"  ‚úÖ Processed data for {name}\")\n",
    "\n",
    "# --- Apply Aggregator Features ---\n",
    "print(\"=== Applying Aggregators ===\")\n",
    "print(\"Rows right after per-player processing :\", len(all_player_data))\n",
    "all_player_data = add_opponent_position_allowed_pts(all_player_data)\n",
    "print(\"Rows after position agg                :\", len(all_player_data))\n",
    "all_player_data = add_team_vs_opponent_allowed_pts(all_player_data)\n",
    "print(\"Rows after team-vs-opp agg             :\", len(all_player_data))\n",
    "\n",
    "\n",
    "#all_player_data = add_opponent_position_allowed_pts(all_player_data)\n",
    "#all_player_data = add_team_vs_opponent_allowed_pts(all_player_data)\n",
    "\n",
    "# --- Train & Evaluate Model ---\n",
    "print(\"\\n=== Training Model ===\")\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_test_original = prepare_data(all_player_data)\n",
    "best_model = train_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "eval_df = evaluate_model(best_model, X_test_scaled, y_test, X_test_original)\n",
    "\n",
    "# --- Next-Game Predictions ---\n",
    "print(\"\\n=== Predicting Next Game Points ===\")\n",
    "from src.prediction import predict_next_game\n",
    "for name in PLAYER_NAMES:\n",
    "    predict_next_game(name, DEFAULT_FEATURE_COLS, season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NBA API\n",
    "from nba_api.stats.endpoints import (\n",
    "    playergamelog, boxscoreadvancedv2,\n",
    "    leaguedashteamstats, scoreboardv2, commonplayerinfo,\n",
    "    leaguegamefinder, boxscoretraditionalv2\n",
    ")\n",
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "# Scikit-Learn & Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor\n",
    ")\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a machine learning model to predict NBA player performance metrics like points involves several steps:\n",
    "\n",
    "Data Collection: Gather historical and current season data using the NBA API, including advanced statistics such as Player Impact Estimate (PIE), Efficiency (EFF), Player Efficiency Rating (PER), trends, opponent data, and more.\n",
    "\n",
    "Data Preprocessing: Clean and preprocess the data to prepare it for modeling.\n",
    "\n",
    "Feature Engineering: Create features that capture the important aspects influencing player performance.\n",
    "\n",
    "Model Training: Choose and train a suitable machine learning model.\n",
    "\n",
    "Model Evaluation: Assess the model's performance and fine-tune as necessary.\n",
    "\n",
    "Prediction: Use the trained model to predict future player performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

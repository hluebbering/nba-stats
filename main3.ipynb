{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use Python and the NBA API to develop advanced machine learning model that predicts player performance metrics in upcoming game\n",
    "\n",
    "\n",
    "<h3 style=\"color:black;font-family:'Segoe UI Variable Display';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;font-weight:300;line-height:1;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Notes from Paris';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;line-height:1;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Juicy Advice Outline';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Mencken Std';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Digital-7';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Proxima Nova';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Barlow Condensed';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "\n",
    "\n",
    "<h3 style=\"color:black;font-family:'Lazy Crunch';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;line-height:1;margin:0;\">Part 2.0</h3>\n",
    "<h3 style=\"color:black;font-family:'Abril Display';font-size:20px;text-shadow:0.125px 0.25px 0.25px black;margin:0;\">Part 2.0</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fetching Data ===\n",
      "üîÑ Loading bulk logs from cache: cache/bulk_logs_2024-25.parquet\n",
      "  ‚úÖ Processed data for Nikola Jokiƒá\n",
      "  ‚úÖ Processed data for Shai Gilgeous-Alexander\n",
      "  ‚úÖ Processed data for Anthony Edwards\n",
      "=== Applying Aggregators ===\n",
      "\n",
      "=== Training Model ===\n",
      "Warning: Missing features skipped: {'PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'REST_DAYS', 'OPP_PTS_2ND_CHANCE', 'PACE_PER40_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'FG_PCT_AVG_LAST_5', 'OPP_PTS_OFF_TOV'}\n",
      "\n",
      "CatBoost Performance:\n",
      "  RMSE: 8.27, MAE: 6.92, R2: 0.24\n",
      "\n",
      "RandomForest Performance:\n",
      "  RMSE: 8.41, MAE: 6.98, R2: 0.22\n",
      "\n",
      "GradientBoosting Performance:\n",
      "  RMSE: 8.71, MAE: 7.17, R2: 0.16\n",
      "\n",
      "Ridge Performance:\n",
      "  RMSE: 7.68, MAE: 6.25, R2: 0.35\n",
      "\n",
      "BayesianRidge Performance:\n",
      "  RMSE: 7.72, MAE: 6.40, R2: 0.34\n",
      "\n",
      "Best model: Ridge with RMSE: 7.68\n",
      "\n",
      "Evaluation on Test Data:\n",
      "  RMSE: 7.68, MAE: 6.25, R2: 0.35\n",
      "\n",
      "=== Predicting Next Game Points ===\n",
      "No next game for Nikola Jokiƒá\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'FG_PCT_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'PACE_PER40_AVG_LAST_5', 'OPPONENT_POSITION_ALLOWED_PTS', 'TEAM_VS_OPP_ALLOWED_PTS'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict_next_game\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m PLAYER_NAMES:\n\u001b[1;32m---> 67\u001b[0m     predict_next_game(name, DEFAULT_FEATURE_COLS, season)\n",
      "File \u001b[1;32mc:\\Users\\luebh\\OneDrive\\Desktop\\hluebbering.github.io\\nba-stats\\src\\prediction.py:107\u001b[0m, in \u001b[0;36mpredict_next_game\u001b[1;34m(player_name, feature_cols, season)\u001b[0m\n\u001b[0;32m    104\u001b[0m     latest[col] \u001b[38;5;241m=\u001b[39m opp_def\u001b[38;5;241m.\u001b[39mget(col, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# 5) Predict\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m fv \u001b[38;5;241m=\u001b[39m latest[feature_cols]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlib/scaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m fv_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(fv, columns\u001b[38;5;241m=\u001b[39mfeature_cols)\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with(key)\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1194\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luebh\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'FG_PCT_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'PACE_PER40_AVG_LAST_5', 'OPPONENT_POSITION_ALLOWED_PTS', 'TEAM_VS_OPP_ALLOWED_PTS'] not in index\""
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "import pandas as pd\n",
    "\n",
    "from src.data_ingestion import (\n",
    "    fetch_bulk_player_game_logs,\n",
    "    get_player_game_logs,\n",
    "    get_player_advanced_stats_parallel,\n",
    "    get_opponent_stats      # ‚Üê add this line\n",
    ")\n",
    "from src.feature_engineering import feature_engineering_pipeline\n",
    "from src.model_training import prepare_data, train_models, evaluate_model, DEFAULT_FEATURE_COLS\n",
    "from src.utils import get_player_id, get_team_abbreviation_id_mapping\n",
    "from src.aggregators import (\n",
    "    add_opponent_position_allowed_pts,\n",
    "    add_team_vs_opponent_allowed_pts\n",
    ")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "PLAYER_NAMES = [\n",
    "    \"Nikola Jokiƒá\", \"Shai Gilgeous-Alexander\", \"Anthony Edwards\"\n",
    "]\n",
    "season = '2024-25'\n",
    "\n",
    "# --- Fetch & Process Data ---\n",
    "print(\"=== Fetching Data ===\")\n",
    "bulk_logs_df = fetch_bulk_player_game_logs(season)\n",
    "team_map = get_team_abbreviation_id_mapping()\n",
    "opp_df = get_opponent_stats(season)   # ‚Üê add this line\n",
    "\n",
    "all_player_data = pd.DataFrame()\n",
    "\n",
    "for name in PLAYER_NAMES:\n",
    "    pid = get_player_id(name)\n",
    "    if not pid:\n",
    "        continue\n",
    "\n",
    "    logs = get_player_game_logs(pid, bulk_logs_df)\n",
    "    if logs.empty:\n",
    "        continue\n",
    "\n",
    "    game_ids = logs['GAME_ID'].tolist()\n",
    "    adv_stats = get_player_advanced_stats_parallel(pid, game_ids)\n",
    "    if adv_stats.empty:\n",
    "        continue\n",
    "\n",
    "    logs['PLAYER_NAME'] = name\n",
    "    merged = logs.merge(adv_stats, on=['GAME_ID', 'PLAYER_ID'], how='left')\n",
    "    merged['PLAYER_ID'] = pid\n",
    "\n",
    "    # Feature engineering\n",
    "    processed = feature_engineering_pipeline(merged, team_map=team_map,opp_df=opp_df)\n",
    "    all_player_data = pd.concat([all_player_data, processed], ignore_index=True)\n",
    "    print(f\"  ‚úÖ Processed data for {name}\")\n",
    "\n",
    "# --- Apply Aggregator Features ---\n",
    "print(\"=== Applying Aggregators ===\")\n",
    "all_player_data = add_opponent_position_allowed_pts(all_player_data)\n",
    "all_player_data = add_team_vs_opponent_allowed_pts(all_player_data)\n",
    "\n",
    "# --- Train & Evaluate Model ---\n",
    "print(\"\\n=== Training Model ===\")\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_test_original = prepare_data(all_player_data)\n",
    "best_model = train_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "eval_df = evaluate_model(best_model, X_test_scaled, y_test, X_test_original)\n",
    "\n",
    "# --- Next-Game Predictions ---\n",
    "print(\"\\n=== Predicting Next Game Points ===\")\n",
    "from src.prediction import predict_next_game\n",
    "for name in PLAYER_NAMES:\n",
    "    predict_next_game(name, DEFAULT_FEATURE_COLS, season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NBA API\n",
    "from nba_api.stats.endpoints import (\n",
    "    playergamelog, boxscoreadvancedv2,\n",
    "    leaguedashteamstats, scoreboardv2, commonplayerinfo,\n",
    "    leaguegamefinder, boxscoretraditionalv2\n",
    ")\n",
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "# Scikit-Learn & Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor\n",
    ")\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a machine learning model to predict NBA player performance metrics like points involves several steps:\n",
    "\n",
    "Data Collection: Gather historical and current season data using the NBA API, including advanced statistics such as Player Impact Estimate (PIE), Efficiency (EFF), Player Efficiency Rating (PER), trends, opponent data, and more.\n",
    "\n",
    "Data Preprocessing: Clean and preprocess the data to prepare it for modeling.\n",
    "\n",
    "Feature Engineering: Create features that capture the important aspects influencing player performance.\n",
    "\n",
    "Model Training: Choose and train a suitable machine learning model.\n",
    "\n",
    "Model Evaluation: Assess the model's performance and fine-tune as necessary.\n",
    "\n",
    "Prediction: Use the trained model to predict future player performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1. Utility & Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_player_id(player_name):\n",
    "    \"\"\"Get the NBA player ID given the player's full name.\"\"\"\n",
    "    nba_players = players.get_players()\n",
    "    player = next((p for p in nba_players if p['full_name'].lower() == player_name.lower()), None)\n",
    "    return player['id'] if player else None\n",
    "\n",
    "def get_team_abbreviation_id_mapping():\n",
    "    \"\"\"Return a dict mapping team abbreviations to team IDs.\"\"\"\n",
    "    nba_teams = teams.get_teams()\n",
    "    return {team['abbreviation']: team['id'] for team in nba_teams}\n",
    "\n",
    "def get_player_team_id(player_id):\n",
    "    \"\"\"Get the player's current team ID.\"\"\"\n",
    "    try:\n",
    "        df = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "        return int(df['TEAM_ID'].iloc[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_team_name(team_id):\n",
    "    \"\"\"Get the full team name given the team ID.\"\"\"\n",
    "    nba_teams = teams.get_teams()\n",
    "    team = next((t for t in nba_teams if t['id'] == team_id), None)\n",
    "    return team['full_name'] if team else 'Unknown Team'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "\n",
    "2. Data Fetching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "\n",
    "# Cache the bulk logs so you don‚Äôt hit the API over and over\n",
    "_bulk_logs_cache = None\n",
    "\n",
    "def fetch_bulk_player_game_logs(season='2024-25'):\n",
    "    global _bulk_logs_cache\n",
    "    if _bulk_logs_cache is None:\n",
    "        print(\"Fetching bulk game logs‚Ä¶\")\n",
    "        lg = leaguegamelog.LeagueGameLog(season=season, player_or_team_abbreviation='P', timeout=60)\n",
    "        df = lg.get_data_frames()[0]\n",
    "        df.columns = df.columns.str.upper()\n",
    "        _bulk_logs_cache = df\n",
    "    return _bulk_logs_cache\n",
    "\n",
    "def get_player_game_logs(player_id, season='2024-25'):\n",
    "    \"\"\"\n",
    "    Previously fetched each player‚Äôs logs one by one.\n",
    "    Now pulls the full season at once then filters.\n",
    "    \"\"\"\n",
    "    bulk = fetch_bulk_player_game_logs(season)\n",
    "    player_df = bulk[bulk['PLAYER_ID'] == int(player_id)].copy()\n",
    "    if player_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    # keep column names consistent\n",
    "    return player_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. Data Fetching Functions\n",
    "# =============================================================================\n",
    "\n",
    "# def get_player_game_logs(player_id, season='2024-25'):\n",
    "#     \"\"\"Fetch player game logs for the given season.\"\"\"\n",
    "#     try:\n",
    "#         gamelog = playergamelog.PlayerGameLog(player_id=player_id, season=season, timeout=60)\n",
    "#         df = gamelog.get_data_frames()[0]\n",
    "#         df.columns = df.columns.str.upper()\n",
    "#         return df\n",
    "#     except:\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "def get_player_advanced_stats(player_id, season='2024-25'):\n",
    "    \"\"\"Fetch advanced stats for all games played by the player in the specified season.\"\"\"\n",
    "    gamelog_df = get_player_game_logs(player_id, season)\n",
    "    adv_stats = []\n",
    "    for game_id in gamelog_df['GAME_ID']:\n",
    "        try:\n",
    "            boxscore = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id, timeout=60)\n",
    "            p_stats = boxscore.player_stats.get_data_frame()\n",
    "            p_adv = p_stats[p_stats['PLAYER_ID'] == int(player_id)]\n",
    "            adv_stats.append(p_adv)\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    if adv_stats:\n",
    "        df = pd.concat(adv_stats, ignore_index=True)\n",
    "        return df[['GAME_ID', 'PLAYER_ID', 'USG_PCT', 'PIE', 'TEAM_ID', 'OFF_RATING', 'PACE_PER40']]\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def get_opponent_stats(season='2024-25'):\n",
    "    \"\"\"Fetch opponent defensive stats for all teams.\"\"\"\n",
    "    df = leaguedashteamstats.LeagueDashTeamStats(\n",
    "        season=season, measure_type_detailed_defense='Defense',\n",
    "        per_mode_detailed='PerGame', timeout=60\n",
    "    ).get_data_frames()[0]\n",
    "    return df[['TEAM_ID', 'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "3. Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Feature Engineering\n",
    "# =============================================================================\n",
    "\n",
    "def compute_efficiency(df):\n",
    "    \"\"\"Compute efficiency metric = (PTS + REB + AST + STL + BLK) - (FGA - FGM) - (FTA - FTM) - TOV.\"\"\"\n",
    "    df['EFF'] = (df['PTS'] + df['REB'] + df['AST'] + df['STL'] + df['BLK']\n",
    "                 - (df['FGA'] - df['FGM']) - (df['FTA'] - df['FTM']) - df['TOV'])\n",
    "    return df\n",
    "\n",
    "def compute_true_shooting_percentage(df):\n",
    "    df['TS_DENOM'] = 2 * (df['FGA'] + 0.44 * df['FTA'])\n",
    "    df['TS_PCT'] = df.apply(\n",
    "        lambda row: row['PTS'] / row['TS_DENOM'] if row['TS_DENOM'] != 0 else 0, axis=1\n",
    "    )\n",
    "    df.drop(columns=['TS_DENOM'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_player_position(player_id, cache=None):\n",
    "    if cache is None:\n",
    "        cache = {}\n",
    "    if player_id in cache:\n",
    "        return cache[player_id]\n",
    "    pos = None\n",
    "    try:\n",
    "        info = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "        raw_pos = info.get('POSITION', [''])[0]\n",
    "        if isinstance(raw_pos, str):\n",
    "            main_pos = raw_pos.split('-')[0].title()\n",
    "            if 'Guard' in main_pos:\n",
    "                pos = 'G'\n",
    "            elif 'Forward' in main_pos:\n",
    "                pos = 'F'\n",
    "            elif 'Center' in main_pos:\n",
    "                pos = 'C'\n",
    "    except:\n",
    "        pass\n",
    "    cache[player_id] = pos\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(player_df, adv_df, opp_df, team_map):\n",
    "    # 1) Basic computations\n",
    "    player_df = compute_efficiency(player_df)\n",
    "    player_df = compute_true_shooting_percentage(player_df)\n",
    "\n",
    "    # 2) Merge advanced stats\n",
    "    df = pd.merge(player_df, adv_df, on=['GAME_ID', 'PLAYER_ID'], how='left')\n",
    "    df['OPPONENT_ABBREVIATION'] = df['MATCHUP'].str.split(' ').str[-1]\n",
    "    df['OPPONENT_TEAM_ID'] = df['OPPONENT_ABBREVIATION'].map(team_map)\n",
    "\n",
    "    # 3) Merge defensive stats\n",
    "    if opp_df is not None and not opp_df.empty:\n",
    "        df = pd.merge(df, opp_df, left_on='OPPONENT_TEAM_ID', right_on='TEAM_ID', how='left')\n",
    "        for col in ['DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE']:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    # 4) Sort by date and parse\n",
    "    df.sort_values(['PLAYER_NAME', 'GAME_DATE'], inplace=True)\n",
    "    df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'], errors='coerce')\n",
    "\n",
    "    # 5) Convert minutes to float\n",
    "    def parse_minutes(x):\n",
    "        if isinstance(x, str) and ':' in x:\n",
    "            mins, secs = x.split(':')\n",
    "            return float(mins) + float(secs)/60\n",
    "        return float(x) if pd.notna(x) else 0\n",
    "\n",
    "    df['MIN'] = df['MIN'].apply(parse_minutes)\n",
    "    df['FG_PCT'] = df['FGM'] / df['FGA'].replace(0, np.nan)\n",
    "\n",
    "    # 6) Compute rolling stats\n",
    "    rolling_cols = ['PIE', 'USG_PCT', 'PTS', 'REB', 'AST', 'EFF', 'TS_PCT', 'MIN', 'FG_PCT', 'OFF_RATING', 'PACE_PER40']\n",
    "    for c in rolling_cols:\n",
    "        df[f'{c}_AVG_LAST_5'] = (df.groupby('PLAYER_NAME')[c]\n",
    "                                 .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean()))\n",
    "        \n",
    "    for c in ['PTS', 'USG_PCT', 'MIN']:\n",
    "        df[f'{c}_VOL_LAST_5'] = (df.groupby('PLAYER_NAME')[c]\n",
    "                                 .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).std()))\n",
    "\n",
    "    # 7) Compute season average for PTS\n",
    "    df['PTS_SEASON_AVG'] = (df.groupby('PLAYER_NAME')['PTS']\n",
    "                              .transform(lambda x: x.shift(1).expanding().mean()))\n",
    "\n",
    "    # 8) Additional features\n",
    "    df['HOME_GAME'] = df['MATCHUP'].apply(lambda x: 1 if 'vs.' in x else 0)\n",
    "    df['REST_DAYS'] = df.groupby('PLAYER_NAME')['GAME_DATE'].diff().dt.days.fillna(0)\n",
    "\n",
    "    # Rename and drop extraneous columns\n",
    "    if 'TEAM_ID_x' in df.columns:\n",
    "        df.rename(columns={'TEAM_ID_x': 'TEAM_ID'}, inplace=True)\n",
    "    df.drop(columns=['TEAM_ID_y'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Forward/back fill to handle any missing rolling stats\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. Aggregator Functions (Position & Team vs Opponent)\n",
    "# =============================================================================\n",
    "\n",
    "def add_player_position(df):\n",
    "    \"\"\"Add a 'POSITION' column (G, F, C) to each row.\"\"\"\n",
    "    cache = {}\n",
    "    df['POSITION'] = df['PLAYER_ID'].apply(lambda pid: get_player_position(pid, cache))\n",
    "    return df.dropna(subset=['POSITION'])\n",
    "\n",
    "def compute_position_allowed_pts(df):\n",
    "    \"\"\"Calculate how many points each team concedes on average to a specific position.\"\"\"\n",
    "    agg = df.groupby(['OPPONENT_TEAM_ID', 'POSITION'])['PTS'].mean().reset_index()\n",
    "    agg.rename(columns={'PTS': 'OPPONENT_POSITION_ALLOWED_PTS'}, inplace=True)\n",
    "    return agg\n",
    "\n",
    "def add_opponent_position_allowed_pts(df):\n",
    "    \"\"\"Merge the 'OPPONENT_POSITION_ALLOWED_PTS' back to the main DataFrame.\"\"\"\n",
    "    df_pos = add_player_position(df)\n",
    "    agg = compute_position_allowed_pts(df_pos)\n",
    "    return pd.merge(df_pos, agg, on=['OPPONENT_TEAM_ID', 'POSITION'], how='left')\n",
    "\n",
    "def compute_team_vs_opponent_allowed_pts(df):\n",
    "    \"\"\"Compute average points a TEAM_ID scores vs. a specific OPPONENT_TEAM_ID.\"\"\"\n",
    "    agg = (df.groupby(['TEAM_ID', 'OPPONENT_TEAM_ID'])['PTS']\n",
    "             .mean().reset_index(name='TEAM_VS_OPP_ALLOWED_PTS'))\n",
    "    return agg\n",
    "\n",
    "def add_team_vs_opponent_allowed_pts(df):\n",
    "    \"\"\"Merge 'TEAM_VS_OPP_ALLOWED_PTS' back to the main DataFrame.\"\"\"\n",
    "    agg = compute_team_vs_opponent_allowed_pts(df)\n",
    "    return pd.merge(df, agg, on=['TEAM_ID', 'OPPONENT_TEAM_ID'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "4. Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. Data Splitting & Preparation\n",
    "# =============================================================================\n",
    "\n",
    "DEFAULT_FEATURE_COLS = [\n",
    "    'PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'EFF_AVG_LAST_5', 'TS_PCT_AVG_LAST_5',\n",
    "    'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE', 'HOME_GAME', 'REST_DAYS',\n",
    "    'PTS_AVG_LAST_5', 'REB_AVG_LAST_5', 'AST_AVG_LAST_5', 'FG_PCT_AVG_LAST_5',\n",
    "    'MIN_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'PACE_PER40_AVG_LAST_5', 'PTS_SEASON_AVG', \n",
    "    'OPPONENT_POSITION_ALLOWED_PTS', 'TEAM_VS_OPP_ALLOWED_PTS',\n",
    "    'PTS_VOL_LAST_5', 'USG_PCT_VOL_LAST_5', 'MIN_VOL_LAST_5',\n",
    "    #'STARTERS_MISSING'  # newly added feature\n",
    "]\n",
    "feature_columns_list = ['PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'EFF_AVG_LAST_5', 'TS_PCT_AVG_LAST_5',\n",
    "    'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE', 'HOME_GAME', 'REST_DAYS',\n",
    "    'PTS_AVG_LAST_5', 'REB_AVG_LAST_5', 'AST_AVG_LAST_5', 'FG_PCT_AVG_LAST_5',\n",
    "    'MIN_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'PACE_PER40_AVG_LAST_5', 'PTS_SEASON_AVG', \n",
    "    'OPPONENT_POSITION_ALLOWED_PTS', 'TEAM_VS_OPP_ALLOWED_PTS',\n",
    "    'PTS_VOL_LAST_5', 'USG_PCT_VOL_LAST_5', 'MIN_VOL_LAST_5',\n",
    "    #'STARTERS_MISSING'  # newly added feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, feature_cols=DEFAULT_FEATURE_COLS):\n",
    "    df = df.dropna(subset=feature_cols)\n",
    "    X = df[feature_cols].copy()\n",
    "    X['PLAYER_NAME'] = df['PLAYER_NAME'] # Keep player_name for reference\n",
    "    y = df['PTS']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    X_test_original = X_test.copy() # Keep a copy of X_test before scaling\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.drop(columns=['PLAYER_NAME']))\n",
    "    X_test_scaled = scaler.transform(X_test.drop(columns=['PLAYER_NAME']))\n",
    "\n",
    "    os.makedirs('lib', exist_ok=True)\n",
    "    joblib.dump(scaler, 'lib/scaler.pkl')\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, X_test_original #X_test['PLAYER_NAME'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "\n",
    "5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. Modeling & Evaluation\n",
    "# =============================================================================\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'CatBoost': CatBoostRegressor(random_state=42, verbose=0),\n",
    "        'RandomForest': RandomForestRegressor(random_state=42),\n",
    "        'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "        'Ridge': Ridge(),\n",
    "        'BayesianRidge': BayesianRidge(),\n",
    "        #'Lasso': Lasso(),\n",
    "        #'ElasticNet': ElasticNet(),\n",
    "        #'LassoLars': LassoLars(),\n",
    "        #'SGDRegressor': SGDRegressor(),\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        print(f\"\\n{name} Performance:\\n  RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "\n",
    "    print(f\"\\nBest model: {type(best_model).__name__} with RMSE: {best_rmse:.2f}\")\n",
    "    return best_model\n",
    "\n",
    "def evaluate_model(model, X_test_scaled, y_test, X_test_original):\n",
    "    preds = model.predict(X_test_scaled) # Make predictions\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds)) # Evaluate metrics\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"\\nEvaluation on Test Data:\\n  RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.2f}\")\n",
    "    \n",
    "    # Build eval_df \n",
    "    eval_df = X_test_original.reset_index(drop=True).copy()\n",
    "    eval_df['Actual_PTS']    = y_test.reset_index(drop=True)\n",
    "    eval_df['Predicted_PTS'] = preds\n",
    "    eval_df['Residual'] = eval_df['Actual_PTS'] - eval_df['Predicted_PTS']\n",
    "    \n",
    "    print(\"\\nSample Predictions:\")\n",
    "    print(eval_df[['PLAYER_NAME', 'Actual_PTS', 'Predicted_PTS', 'Residual']].head(10))    \n",
    "    return eval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "7. Model Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. Next-Game Prediction Logic\n",
    "# =============================================================================\n",
    "\n",
    "def get_team_defensive_stats(team_id, season='2024-25'):\n",
    "    try:\n",
    "        df = leaguedashteamstats.LeagueDashTeamStats(\n",
    "            team_id_nullable=team_id, season=season,\n",
    "            measure_type_detailed_defense='Defense', per_mode_detailed='PerGame',\n",
    "            timeout=60\n",
    "        ).get_data_frames()[0]\n",
    "        return df[['TEAM_ID', 'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE']].iloc[0]\n",
    "    except:\n",
    "        return pd.Series([np.nan]*4, index=['TEAM_ID', 'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE'])\n",
    "\n",
    "\n",
    "def get_next_game_info(player_team_id):\n",
    "    next_game_date = datetime.now() #+ timedelta(days=1)\n",
    "    max_days_ahead = 14\n",
    "\n",
    "    for _ in range(max_days_ahead):\n",
    "        game_date_str = next_game_date.strftime('%Y-%m-%d')\n",
    "        try:\n",
    "            scoreboard = scoreboardv2.ScoreboardV2(game_date=game_date_str)\n",
    "            games = scoreboard.game_header.get_data_frame()\n",
    "            team_games = games[(games['HOME_TEAM_ID'] == player_team_id) | (games['VISITOR_TEAM_ID'] == player_team_id)]\n",
    "            if not team_games.empty:\n",
    "                next_game = team_games.iloc[0]\n",
    "                opponent_team_id = next_game['VISITOR_TEAM_ID'] if next_game['HOME_TEAM_ID'] == player_team_id else next_game['HOME_TEAM_ID']\n",
    "                home_game = 1 if next_game['HOME_TEAM_ID'] == player_team_id else 0\n",
    "                return next_game_date, opponent_team_id, home_game\n",
    "        except:\n",
    "            pass\n",
    "        next_game_date += timedelta(days=1)\n",
    "\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_prediction(player_id, player_name, season='2024-25', feature_cols=DEFAULT_FEATURE_COLS, \n",
    "                                    df_agg_position=None, df_agg_team_vs_opp=None):\n",
    "    # 1) Pull player's logs and advanced stats.\n",
    "    logs_df = get_player_game_logs(player_id, season)\n",
    "    if logs_df.empty:\n",
    "        print(f\"No game logs for {player_name} in {season}.\")\n",
    "        return None, None\n",
    "    logs_df['GAME_DATE'] = pd.to_datetime(logs_df['GAME_DATE'])\n",
    "    logs_df.sort_values('GAME_DATE', ascending=False, inplace=True)\n",
    "    logs_df['PLAYER_NAME'] = player_name\n",
    "\n",
    "    # Team & next game\n",
    "    p_team_id = get_player_team_id(player_id)\n",
    "    next_game_date, opp_team_id, home_game = get_next_game_info(p_team_id)\n",
    "    if not next_game_date:\n",
    "        print(f\"No upcoming game found for {player_name}.\")\n",
    "        return None, None\n",
    "\n",
    "    # Opponent stats\n",
    "    opp_stats = get_team_defensive_stats(opp_team_id, season)\n",
    "    # Advanced stats\n",
    "    adv_df = get_player_advanced_stats(player_id, season)\n",
    "\n",
    "    # Build a small historical subset\n",
    "    team_map = get_team_abbreviation_id_mapping()\n",
    "    recent_logs = logs_df[logs_df['GAME_DATE'] <= logs_df['GAME_DATE'].max()]\n",
    "    adv_df = adv_df[adv_df['GAME_ID'].isin(recent_logs['GAME_ID'])]\n",
    "    final_df = feature_engineering(recent_logs, adv_df, None, team_map)\n",
    "\n",
    "    if final_df.empty:\n",
    "        return None, None\n",
    "\n",
    "    # 2) Feature-engineer a 'latest_data' row (from last game).\n",
    "    # 3) Insert upcoming game info: rest days, home/away, opponent stats.\n",
    "    latest_data = final_df.iloc[-1].copy()\n",
    "    latest_data['REST_DAYS'] = (next_game_date - latest_data['GAME_DATE']).days\n",
    "    latest_data['HOME_GAME'] = home_game\n",
    "    latest_data['GAME_DATE'] = next_game_date\n",
    "    latest_data['OPPONENT_TEAM_ID'] = opp_team_id\n",
    "    latest_data['DEF_RATING'] = opp_stats['DEF_RATING']\n",
    "    latest_data['OPP_PTS_OFF_TOV'] = opp_stats['OPP_PTS_OFF_TOV']\n",
    "    latest_data['OPP_PTS_2ND_CHANCE'] = opp_stats['OPP_PTS_2ND_CHANCE']\n",
    "    \n",
    "    # 4) Merge aggregator stats for position and team vs. opponent.\n",
    "    # Position-based aggregator\n",
    "    if df_agg_position is not None:\n",
    "        pos = get_player_position(player_id)\n",
    "        if not pos:  # fallback\n",
    "            pos = 'G'\n",
    "        row_match = df_agg_position[\n",
    "            (df_agg_position['OPPONENT_TEAM_ID'] == opp_team_id) & (df_agg_position['POSITION'] == pos)\n",
    "        ]\n",
    "        if not row_match.empty:\n",
    "            latest_data['OPPONENT_POSITION_ALLOWED_PTS'] = row_match['OPPONENT_POSITION_ALLOWED_PTS'].iloc[0]\n",
    "        else:\n",
    "            # fallback to position average\n",
    "            fallback_pos = df_agg_position[df_agg_position['POSITION'] == pos]\n",
    "            latest_data['OPPONENT_POSITION_ALLOWED_PTS'] = fallback_pos['OPPONENT_POSITION_ALLOWED_PTS'].mean()\n",
    "\n",
    "    # Team vs Opp aggregator\n",
    "    if df_agg_team_vs_opp is not None:\n",
    "        row_match = df_agg_team_vs_opp[\n",
    "            (df_agg_team_vs_opp['TEAM_ID'] == p_team_id) & (df_agg_team_vs_opp['OPPONENT_TEAM_ID'] == opp_team_id)\n",
    "        ]\n",
    "        if not row_match.empty:\n",
    "            latest_data['TEAM_VS_OPP_ALLOWED_PTS'] = row_match['TEAM_VS_OPP_ALLOWED_PTS'].iloc[0]\n",
    "        else:\n",
    "            latest_data['TEAM_VS_OPP_ALLOWED_PTS'] = df_agg_team_vs_opp['TEAM_VS_OPP_ALLOWED_PTS'].mean()\n",
    "\n",
    "    # Build the final feature vector\n",
    "    try:\n",
    "        fv = latest_data[feature_cols].values.reshape(1, -1)\n",
    "        return fv, latest_data\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing columns for {player_name}: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_upcoming_points(player_name, season='2024-25', feature_cols=DEFAULT_FEATURE_COLS, \n",
    "                            df_agg_position=None, df_agg_team_vs_opp=None):\n",
    "    player_id = get_player_id(player_name)\n",
    "    if not player_id:\n",
    "        print(f\"Invalid player: {player_name}\")\n",
    "        return None\n",
    "\n",
    "    fv, latest_data = prepare_features_for_prediction(player_id, player_name, season, feature_cols=feature_cols,\n",
    "                                                      df_agg_position=df_agg_position, df_agg_team_vs_opp=df_agg_team_vs_opp)\n",
    "    if fv is None:\n",
    "        return None\n",
    "    \n",
    "    # Scale & predict\n",
    "    scaler = joblib.load('lib/scaler.pkl')\n",
    "    model = joblib.load('lib/player_points_model.pkl')\n",
    "    fv_scaled = scaler.transform(fv)\n",
    "    pred = model.predict(fv_scaled)\n",
    "    opp_name = get_team_name(latest_data['OPPONENT_TEAM_ID'])\n",
    "    date_str = latest_data['GAME_DATE'].strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"Predicted points for {player_name} on {date_str} vs {opp_name}: {pred[0]:.2f}\")\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "8. Feature Importance\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. Example Usage \n",
    "# =============================================================================\n",
    "\n",
    "player_names = [\n",
    "    \"LeBron James\", \"Stephen Curry\", \"Giannis Antetokounmpo\", \"Luka Donƒçiƒá\", \n",
    "    # \"Kevin Durant\", \"Joel Embiid\", \"Victor Wembanyama\", \"Damian Lillard\", \"Anthony Davis\", \"Domantas Sabonis\",\n",
    "    \"Jayson Tatum\", \"Nikola Jokiƒá\", \"Shai Gilgeous-Alexander\", \"Karl-Anthony Towns\",\n",
    "    \"Donovan Mitchell\", \"James Harden\", \"Anthony Edwards\", \"Jimmy Butler\",\n",
    "    # \"Kyrie Irving\", \"De'Aaron Fox\", #\"Bronny James\", \"Zion Williamson\", \"Tyrese Maxey\", \n",
    "    \"Jalen Brunson\", \"Trae Young\", \"Pascal Siakam\", \"Jalen Green\",\n",
    "    \"Darius Garland\", \"Jalen Williams\", \"Jaylen Brown\",  \"Paolo Bunchero\",\n",
    "    \"Norman Powell\", \"Alperen ≈ûeng√ºn\", \"Ja Morant\", \"Jaren Jackson Jr.\",\n",
    "    ]\n",
    "\n",
    "season = '2024-25'\n",
    "opponent_stats = get_opponent_stats(season)\n",
    "team_map = get_team_abbreviation_id_mapping()\n",
    "\n",
    "all_player_data = pd.DataFrame()\n",
    "for p_name in player_names:\n",
    "    p_id = get_player_id(p_name)\n",
    "    if not p_id:\n",
    "        continue\n",
    "    p_gamelog = get_player_game_logs(p_id, season)\n",
    "    adv_stats = get_player_advanced_stats(p_id, season)\n",
    "    if p_gamelog.empty or adv_stats.empty:\n",
    "        continue\n",
    "    \n",
    "    p_gamelog['PLAYER_NAME'] = p_name\n",
    "    merged_df = feature_engineering(p_gamelog, adv_stats, opponent_stats, team_map)\n",
    "    all_player_data = pd.concat([all_player_data, merged_df], ignore_index=True)\n",
    "\n",
    "# 3) Position & Team aggregator\n",
    "all_player_data = add_opponent_position_allowed_pts(all_player_data)\n",
    "all_player_data = add_team_vs_opponent_allowed_pts(all_player_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled, X_test_scaled, y_train, y_test, p_names_test = prepare_data(all_player_data)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_test_original = prepare_data(all_player_data) \n",
    "best_model = train_and_evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "joblib.dump(best_model, 'lib/player_points_model.pkl')\n",
    "\n",
    "# Build eval_df for residual analysis | after training:\n",
    "eval_df = evaluate_model(best_model, X_test_scaled, y_test, X_test_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Predict upcoming game for each player\n",
    "#    (requires the aggregator dataframes if we want position-based features)\n",
    "df_agg_position = compute_position_allowed_pts(all_player_data)  # merges OPP_TEAM & POSITION -> mean(PTS)\n",
    "df_agg_team_opp = compute_team_vs_opponent_allowed_pts(all_player_data)\n",
    "for name in player_names:\n",
    "    predict_upcoming_points(\n",
    "        name, season, df_agg_position=df_agg_position, df_agg_team_vs_opp=df_agg_team_opp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "###### Evaluation Residuals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now we can do residual analysis\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(eval_df['Residual'], kde=True, bins=20)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Starters Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Time Series Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def time_series_cv_evaluation(df, feature_cols, target_col='PTS', n_splits=5):\n",
    "    \"\"\"Perform time-series cross-validation with n_splits folds.\"\"\"\n",
    "    # Sort by date\n",
    "    df_sorted = df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
    "    X_full = df_sorted[feature_cols].copy()\n",
    "    y_full = df_sorted[target_col].values\n",
    "\n",
    "    # Prepare cross-validator\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    fold_number = 1\n",
    "    for train_index, val_index in tscv.split(X_full):\n",
    "        X_train, X_val = X_full.iloc[train_index], X_full.iloc[val_index] # Split\n",
    "        y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        scaler = StandardScaler() # Scale\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "        # (You can choose whichever model you want here. Let's do a simple RandomForest as an example.)\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict\n",
    "        val_preds = model.predict(X_val_scaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "        r2 = model.score(X_val_scaled, y_val)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"Fold {fold_number} RMSE = {rmse:.3f} R-Squared = {r2:.3f}\")\n",
    "        fold_number += 1\n",
    "\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    print(f\"\\nAverage RMSE over {n_splits} folds: {avg_rmse:.3f}\")\n",
    "    print(f\"\\nAverage R-Squared over {n_splits} folds: {avg_r2:.3f}\")\n",
    "    return avg_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_cv_evaluation(all_player_data, DEFAULT_FEATURE_COLS, target_col='PTS', n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Position and Role-Based Features:\n",
    "\n",
    "Include data about the player's role (e.g., starter vs. bench), player position, and how the upcoming opponent typically defends that position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.build_player_team_data import main\n",
    "df_player_full = main(season='2024-25', data_file=\"data/merged_player_team_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hyperparameter Tuning and Bayesian Optimization:\n",
    "Instead of a simple grid search, use advanced hyperparameter optimization methods (e.g., Bayesian optimization or Optuna) to find the best parameters for CatBoost, XGBoost, LightGBM, or neural networks.\n",
    "Non-Linear Models and Neural Networks:\n",
    "Consider deep learning approaches. A simple feed-forward neural network or LSTM/RNN if you structure your data as a time series could capture temporal dependencies more effectively.\n",
    "Time-Series Aware Validation:\n",
    "\n",
    "Ensure you use proper time-series cross-validation (e.g., TimeSeriesSplit) so the model isn't accidentally leaking future information.\n",
    "\n",
    "\n",
    "Betting Lines or Market Data:\n",
    "Market-based indicators (like the Vegas over/under for the game) can indirectly capture external knowledge about expected scoring environment.\n",
    "\n",
    "\n",
    "Dimensionality Reduction and Feature Selection:\n",
    "\n",
    "Feature Importance and Pruning:\n",
    "Use model explainability tools (SHAP, feature_importances_) to identify less useful features and remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Star Player Out\n",
    "\n",
    "Handling Injuries / Roster Changes\n",
    "\n",
    "If a key teammate is absent, a star player‚Äôs usage might spike. Consider adding a feature that tracks ‚Äúnumber of typical starters missing‚Äù for a given game. That often impacts scoring opportunities.\n",
    "\n",
    "Explainability\n",
    "\n",
    "Tools like SHAP or feature importances from tree-based models can help you see which inputs drive the predictions. This can help you debug or refine features.\n",
    "\n",
    "\n",
    "\n",
    "######  Pipeline Packaging\n",
    "\n",
    "Once stable, you can wrap the entire pipeline in a script (or notebook) that daily:\n",
    "Pulls updated logs.\n",
    "Retrains/updates model (if desired) or just re-scores with the existing model.\n",
    "Outputs next-game predictions to a CSV or database.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n",
    "# Injury Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_espn_injuries(url=\"https://www.espn.com/nba/injuries\"):\n",
    "    \"\"\"Returns a DataFrame with columns: [TEAM_NAME, PLAYER_NAME, POS, EST_RETURN, STATUS, COMMENT].\"\"\"\n",
    "    # 1) Add headers that mimic a real browser\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/107.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    # 2) Make the request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 3) Parse HTML\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # 4) The main container for injuries is identified by:\n",
    "    #    <div class=\"ResponsiveTable Table__league-injuries\"> ...table content...\n",
    "    #    We'll find all such sections for different teams.\n",
    "\n",
    "    # \"ResponsiveTable Table__league-injuries\" is repeated per team\n",
    "    # We might see multiple <div> blocks with that class\n",
    "    team_tables = soup.find_all(\"div\", class_=\"ResponsiveTable Table__league-injuries\")\n",
    "\n",
    "    all_rows = [] # We'll store results in a list of dicts\n",
    "\n",
    "    for table_div in team_tables:\n",
    "        # Each 'table_div' should contain a <div class=\"Table__Title\"> for the team name\n",
    "        # and a <table> with <thead>/<tbody> for the injuries.\n",
    "\n",
    "        # 1) Get the Team Name\n",
    "        title_div = table_div.find(\"div\", class_=\"Table__Title\")\n",
    "        if not title_div:\n",
    "            # If we can't find the title, skip\n",
    "            continue\n",
    "\n",
    "        # The team name is often in: <span class=\"injuries__teamName ...\">TEAM NAME</span>\n",
    "        team_name_span = title_div.find(\"span\", class_=\"injuries__teamName\")\n",
    "        if not team_name_span:\n",
    "            continue\n",
    "        team_name = team_name_span.get_text(strip=True)\n",
    "\n",
    "        # 2) The <table> has a <thead> and <tbody> with multiple <tr> rows.\n",
    "        # Typically: <tbody class=\"Table__TBODY\"><tr> ... <td> ... etc.\n",
    "        table_tag = table_div.find(\"table\", class_=\"Table\")\n",
    "        if not table_tag:\n",
    "            continue\n",
    "\n",
    "        tbody = table_tag.find(\"tbody\", class_=\"Table__TBODY\")\n",
    "        if not tbody:\n",
    "            continue\n",
    "\n",
    "        # 3) Each row in the <tbody> is one player's injury record\n",
    "        rows = tbody.find_all(\"tr\", class_=\"Table__TR\")\n",
    "        for row in rows:\n",
    "            # We have multiple <td> columns: NAME, POS, EST. RETURN DATE, STATUS, COMMENT\n",
    "            tds = row.find_all(\"td\", class_=\"Table__TD\")\n",
    "            if len(tds) < 5:\n",
    "                # Expect at least 5 columns\n",
    "                continue\n",
    "\n",
    "            player_name = tds[0].get_text(strip=True)\n",
    "            pos = tds[1].get_text(strip=True)\n",
    "            est_return = tds[2].get_text(strip=True)\n",
    "            status = tds[3].get_text(strip=True)\n",
    "            comment = tds[4].get_text(strip=True)\n",
    "\n",
    "            # Store in a dict\n",
    "            all_rows.append({\n",
    "                \"TEAM_NAME\": team_name,\n",
    "                \"PLAYER_NAME\": player_name,\n",
    "                \"POS\": pos,\n",
    "                \"EST_RETURN\": est_return,\n",
    "                \"STATUS\": status, \n",
    "                \"COMMENT\": comment\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_injury = pd.DataFrame(all_rows)\n",
    "    return df_injury\n",
    "\n",
    "\n",
    "df_injury = scrape_espn_injuries(\"https://www.espn.com/nba/injuries\")\n",
    "if df_injury.empty:\n",
    "    print(\"No data or scraping failed.\")\n",
    "\n",
    "# Add a DATA_DATE\n",
    "df_injury[\"DATA_DATE\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = f\"data/injury_reports/injury_report_{df_injury['DATA_DATE'].iloc[0]}.csv\"\n",
    "df_injury.to_csv(csv_file, index=False)\n",
    "print(f\"Saved injury data to {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injury.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star Player Identification\n",
    "\n",
    "You can use ‚Äútypical_starters_dict‚Äù or any advanced approach to identify who‚Äôs considered a ‚Äúkey player‚Äù for each team. Then, if they‚Äôre out, your model can see a bigger effect on the minutes or usage of the rest of the team.\n",
    "\n",
    "Minutes vs. Points\n",
    "\n",
    "Often, you‚Äôll first build a minutes model (that uses IS_OUT, TEAM_HAS_STAR_OUT) and outputs MIN_PROJ. Then you feed MIN_PROJ + other features into your points model.\n",
    "The partial historical injuries help that minutes model learn ‚ÄúWhen star is out, player X‚Äôs minutes jump by 5.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pipeline Automation & Data Storage\n",
    "4.1 Scheduled Updates\n",
    "Set up a daily or weekly job that:\n",
    "Pulls fresh game logs and advanced box scores via the NBA API (or your own data store).\n",
    "Updates your training dataset.\n",
    "Optionally retrains or re-fits the model.\n",
    "Generates new next-game predictions for each player.\n",
    "4.2 Data Storage\n",
    "Use a database (e.g., SQLite, PostgreSQL) or a Cloud Data Warehouse (BigQuery, Snowflake) to store:\n",
    "Historical game logs\n",
    "Player metadata (e.g., birthdate, draft year, position, injuries)\n",
    "Team stats / synergy metrics\n",
    "This central repository simplifies repeated queries and ensures you have a single source of truth.\n",
    "4.3 Version Control & Logging\n",
    "Version your model artifacts (e.g., model_v1.0.pkl, model_v1.1.pkl) and keep a record of:\n",
    "Date of training\n",
    "Hyperparameters\n",
    "Performance metrics\n",
    "Log daily predictions and compare them later to actual game results to measure real-time accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". Perform a Residual Analysis\n",
    "Generate a residual DataFrame: df_residuals = actual_points - predicted_points.\n",
    "Plot histograms, scatter plots (residuals vs. minutes or usage), or groupby stats (residuals by team or position).\n",
    "Look for patterns that might suggest missing features or systematic biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.cleanup_script import remove_markdown_blocks_and_reformat\n",
    "\n",
    "remove_markdown_blocks_and_reformat(\"notebooks/test.py\", \"notebooks/test_cleaned.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamplayerdashboard\n",
    "\n",
    "def get_top_5_players_by_minutes(team_id, season='2024-25'):\n",
    "    \"\"\"\n",
    "    Return a list of the player IDs of the top 5 players on a given team,\n",
    "    sorted by average minutes played in that season.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # teamplayerdashboard gives per-game stats for each player on the team\n",
    "        dashboard = teamplayerdashboard.TeamPlayerDashboard(\n",
    "            team_id=team_id,\n",
    "            season=season,\n",
    "            per_mode_detailed='PerGame',\n",
    "            timeout=60\n",
    "        )\n",
    "        df_players = dashboard.get_data_frames()[1]  # [1] is the TeamPlayerDashboard table\n",
    "        df_players = df_players.sort_values('MIN', ascending=False)\n",
    "        # Return top 5 player IDs\n",
    "        return df_players['PLAYER_ID'].head(5).tolist()\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def build_team_starters_dict(unique_team_ids, season='2024-25'):\n",
    "    \"\"\"\n",
    "    Build a dictionary that maps each TEAM_ID -> list of top-5 starter player IDs.\n",
    "    \"\"\"\n",
    "    team_starters = {}\n",
    "    for tid in unique_team_ids:\n",
    "        top_5_list = get_top_5_players_by_minutes(tid, season)\n",
    "        team_starters[tid] = top_5_list\n",
    "    return team_starters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import boxscoretraditionalv2\n",
    "\n",
    "def compute_starters_missing_for_games(df, team_starters, season='2024-25'):\n",
    "    \"\"\"\n",
    "    For each unique GAME_ID in df, fetch the box score. \n",
    "    Count how many of each team's top-5 starters did not play.\n",
    "    Return a dict with keys = (GAME_ID, TEAM_ID) and values = number_of_missing_starters.\n",
    "    \"\"\"\n",
    "    # Collect unique game IDs\n",
    "    unique_game_ids = df['GAME_ID'].unique().tolist()\n",
    "    \n",
    "    # We'll store our results in a dict:  {(game_id, team_id): missing_count}\n",
    "    missing_starters_dict = {}\n",
    "    \n",
    "    for game_id in unique_game_ids:\n",
    "        try:\n",
    "            # Pull the boxscore\n",
    "            boxscore = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=game_id, timeout=60)\n",
    "            box_df = boxscore.get_data_frames()[0]\n",
    "            \n",
    "            # Filter only those who actually played (MIN > 0) \n",
    "            # or you can check if \"PLAYER_NAME\" is present, etc.\n",
    "            players_who_played = box_df[box_df['MIN'] != '0:00']['PLAYER_ID'].unique().tolist()\n",
    "            \n",
    "            # Now box_df also has a 'TEAM_ID' column. We'll iterate by team to see who missed the game\n",
    "            for tid in box_df['TEAM_ID'].unique():\n",
    "                top_5 = team_starters.get(tid, [])\n",
    "                if not top_5: \n",
    "                    # if no data, assume zero missing for safety\n",
    "                    missing_starters_dict[(game_id, tid)] = 0\n",
    "                    continue\n",
    "\n",
    "                missing_count = sum(player_id not in players_who_played for player_id in top_5)\n",
    "                missing_starters_dict[(game_id, tid)] = missing_count\n",
    "                \n",
    "        except:\n",
    "            # If something fails, fallback to zero missing\n",
    "            for tid in df[df['GAME_ID'] == game_id]['TEAM_ID'].unique():\n",
    "                missing_starters_dict[(game_id, tid)] = 0\n",
    "\n",
    "    return missing_starters_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_starters_missing_features(df, missing_starters_dict):\n",
    "    \"\"\"\n",
    "    For each row in df, add 'TEAM_STARTERS_MISSING' and 'OPP_STARTERS_MISSING'.\n",
    "    We assume 'TEAM_ID' and 'OPPONENT_TEAM_ID' exist in df.\n",
    "    \"\"\"\n",
    "    df['TEAM_STARTERS_MISSING'] = df.apply(\n",
    "        lambda row: missing_starters_dict.get((row['GAME_ID'], row['TEAM_ID']), 0),\n",
    "        axis=1\n",
    "    )\n",
    "    df['OPP_STARTERS_MISSING'] = df.apply(\n",
    "        lambda row: missing_starters_dict.get((row['GAME_ID'], row['OPPONENT_TEAM_ID']), 0),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from nba_api.stats.endpoints import boxscoretraditionalv2\n",
    "\n",
    "def fetch_boxscore(game_id):\n",
    "    \"\"\"\n",
    "    Fetch box score data for a single GAME_ID.\n",
    "    Returns a DataFrame. If API call fails, returns empty DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        boxscore = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=game_id, timeout=60)\n",
    "        return boxscore.get_data_frames()[0]\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def compute_starters_missing_for_games(df, team_starters, season='2024-25', max_workers=8):\n",
    "    \"\"\"\n",
    "    For each unique GAME_ID in df, fetch the box score in parallel.\n",
    "    Then compute how many of each team's top-5 starters did not play.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns including 'GAME_ID' and 'TEAM_ID'.\n",
    "        team_starters (dict): {TEAM_ID -> [top5_player_ids]}\n",
    "        season (str): '2024-25' by default.\n",
    "        max_workers (int): Number of threads for parallel requests.\n",
    "\n",
    "    Returns:\n",
    "        dict: {(GAME_ID, TEAM_ID): missing_starters_count}\n",
    "    \"\"\"\n",
    "    unique_game_ids = df['GAME_ID'].unique().tolist()\n",
    "\n",
    "    # 1) Parallel fetch all boxscores for unique_game_ids\n",
    "    boxscore_cache = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_gid = {\n",
    "            executor.submit(fetch_boxscore, gid): gid for gid in unique_game_ids\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_gid):\n",
    "            gid = future_to_gid[future]\n",
    "            try:\n",
    "                boxscore_cache[gid] = future.result()\n",
    "            except Exception as exc:\n",
    "                print(f'[Error] BoxScore fetch failed for {gid}: {exc}')\n",
    "                boxscore_cache[gid] = pd.DataFrame()  # fallback to empty\n",
    "\n",
    "    # 2) For each game, figure out how many top-5 starters didn't play\n",
    "    missing_starters_dict = {}\n",
    "    for game_id, box_df in boxscore_cache.items():\n",
    "        if box_df.empty:\n",
    "            # If we have no data, fallback to 0 for every team in that game\n",
    "            relevant_teams = df[df['GAME_ID'] == game_id]['TEAM_ID'].unique()\n",
    "            for tid in relevant_teams:\n",
    "                missing_starters_dict[(game_id, tid)] = 0\n",
    "            continue\n",
    "\n",
    "        # Filter to players who actually played (MIN != \"0:00\" or \"0\")\n",
    "        # (some boxscores have \"0\" or \"00:00\", so let's handle either).\n",
    "        box_df = box_df[~box_df['MIN'].isin([\"0:00\", \"0\"])]\n",
    "        players_who_played = box_df['PLAYER_ID'].unique().tolist()\n",
    "\n",
    "        # For each team in this boxscore\n",
    "        for tid in box_df['TEAM_ID'].unique():\n",
    "            top5 = team_starters.get(tid, [])\n",
    "            missing_count = sum(pid not in players_who_played for pid in top5)\n",
    "            missing_starters_dict[(game_id, tid)] = missing_count\n",
    "\n",
    "        # Also cover edge cases if some teams in df aren't in box_df\n",
    "        # (rare, but can happen if data is incomplete)\n",
    "        relevant_teams = df[(df['GAME_ID'] == game_id) & (~df['TEAM_ID'].isin(box_df['TEAM_ID'].unique()))]['TEAM_ID'].unique()\n",
    "        for tid in relevant_teams:\n",
    "            missing_starters_dict[(game_id, tid)] = 0\n",
    "\n",
    "    return missing_starters_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FEATURE_COLS = [\n",
    "    'PIE_AVG_LAST_5', 'USG_PCT_AVG_LAST_5', 'EFF_AVG_LAST_5', 'TS_PCT_AVG_LAST_5',\n",
    "    'DEF_RATING', 'OPP_PTS_OFF_TOV', 'OPP_PTS_2ND_CHANCE', 'HOME_GAME', 'REST_DAYS',\n",
    "    'PTS_AVG_LAST_5', 'REB_AVG_LAST_5', 'AST_AVG_LAST_5', 'FG_PCT_AVG_LAST_5',\n",
    "    'MIN_AVG_LAST_5', 'OFF_RATING_AVG_LAST_5', 'PACE_PER40_AVG_LAST_5', 'PTS_SEASON_AVG', \n",
    "    'OPPONENT_POSITION_ALLOWED_PTS', 'TEAM_VS_OPP_ALLOWED_PTS',\n",
    "    'PTS_VOL_LAST_5', 'USG_PCT_VOL_LAST_5', 'MIN_VOL_LAST_5',\n",
    "    'TEAM_STARTERS_MISSING', 'OPP_STARTERS_MISSING',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Below is the full code snippet that puts it all together\n",
    "##########################################################\n",
    "season = '2024-25'\n",
    "opponent_stats = get_opponent_stats(season)\n",
    "team_map = get_team_abbreviation_id_mapping()\n",
    "\n",
    "all_player_data = pd.DataFrame()\n",
    "for p_name in player_names:\n",
    "    p_id = get_player_id(p_name)\n",
    "    if not p_id:\n",
    "        continue\n",
    "    p_gamelog = get_player_game_logs(p_id, season)\n",
    "    adv_stats = get_player_advanced_stats(p_id, season)\n",
    "    if p_gamelog.empty or adv_stats.empty:\n",
    "        continue\n",
    "    \n",
    "    p_gamelog['PLAYER_NAME'] = p_name\n",
    "    merged_df = feature_engineering(p_gamelog, adv_stats, opponent_stats, team_map)\n",
    "    all_player_data = pd.concat([all_player_data, merged_df], ignore_index=True)\n",
    "\n",
    "# 3) Position & Team aggregator\n",
    "all_player_data = add_opponent_position_allowed_pts(all_player_data)\n",
    "all_player_data = add_team_vs_opponent_allowed_pts(all_player_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build the dictionary of top-5 starters for each team\n",
    "unique_team_ids = all_player_data['TEAM_ID'].unique().tolist()\n",
    "team_starters_dict = build_team_starters_dict(unique_team_ids, season='2024-25')\n",
    "\n",
    "# 4) Compute how many starters are missing for each game/team\n",
    "missing_starters_dict = compute_starters_missing_for_games(\n",
    "    all_player_data, team_starters_dict, season='2024-25'\n",
    ")\n",
    "\n",
    "# 5) Add the new columns\n",
    "all_player_data = add_starters_missing_features(all_player_data, missing_starters_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Now do train/test split & modeling as usual\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, X_test_original = prepare_data(all_player_data)\n",
    "best_model = train_and_evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "eval_df = evaluate_model(best_model, X_test_scaled, y_test, X_test_original)\n",
    "\n",
    "# Your further steps, such as predictions for upcoming games, residual analysis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_player_data.to_csv('data/all_player_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
